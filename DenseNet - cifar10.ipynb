{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"DenseNet - cifar10.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"fKR5qwXUYnTG","colab_type":"text"},"source":["<h4>CNN on cifar guidelines</h4>\n","\n","1.  Please visit this link to access the state-of-art DenseNet code for reference - DenseNet - cifar10 notebook link\n","2.  You need to create a copy of this and \"retrain\" this model to achieve 90+ test accuracy. \n","3.  You cannot use Dense Layers (also called fully connected layers), or DropOut.\n","4.  You MUST use Image Augmentation Techniques.\n","5.  You cannot use an already trained model as a beginning points, you have to initilize as your own\n","6.  You cannot run the program for more than 300 Epochs, and it should be clear from your log, that you have only used 300 Epochs\n","7.  You cannot use test images for training the model.\n","8.  You cannot change the general architecture of DenseNet (which means you must use Dense Block, Transition and Output blocks as mentioned in the code)\n","9.  You are free to change Convolution types (e.g. from 3x3 normal convolution to Depthwise Separable, etc)\n","10. You cannot have more than 1 Million parameters in total\n","11. You are free to move the code from Keras to Tensorflow, Pytorch, MXNET etc. \n","12. You can use any optimization algorithm you need. \n","13. You can checkpoint your model and retrain the model from that checkpoint so that no need of training the model from first if you lost at any epoch while training. You can directly load that model and Train from that epoch. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"wVIx_KIigxPV","colab":{},"executionInfo":{"status":"ok","timestamp":1597104080884,"user_tz":-330,"elapsed":3033,"user":{"displayName":"Kumar Shwetaketu","photoUrl":"","userId":"02755040458660561297"}}},"source":["# import keras\n","# from keras.datasets import cifar10\n","# from keras.models import Model, Sequential\n","# from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n","# from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n","# from keras.layers import Concatenate\n","# from keras.optimizers import Adam\n","from tensorflow.keras import models, layers\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import BatchNormalization, Activation, Flatten\n","from tensorflow.keras.optimizers import Adam"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"UNHw6luQg3gc","colab":{},"executionInfo":{"status":"ok","timestamp":1597104080889,"user_tz":-330,"elapsed":3028,"user":{"displayName":"Kumar Shwetaketu","photoUrl":"","userId":"02755040458660561297"}}},"source":["# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n","# backend\n","import tensorflow as tf"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"dsO_yGxcg5D8","colab":{},"executionInfo":{"status":"ok","timestamp":1597104080890,"user_tz":-330,"elapsed":3016,"user":{"displayName":"Kumar Shwetaketu","photoUrl":"","userId":"02755040458660561297"}}},"source":["# Hyperparameters\n","batch_size = 128\n","num_classes = 10\n","epochs = 200\n","l = 40\n","num_filter = 20\n","compression = 0.5\n","dropout_rate = 0.2"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"mB7o3zu1g6eT","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1597104086855,"user_tz":-330,"elapsed":8937,"user":{"displayName":"Kumar Shwetaketu","photoUrl":"","userId":"02755040458660561297"}},"outputId":"493445f5-c5be-484c-d3ca-1fe1a474dd9f"},"source":["# Load CIFAR10 Data\n","(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n","img_height, img_width, channel = X_train.shape[1],X_train.shape[2],X_train.shape[3]\n","\n","# convert to one hot encoing \n","y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n","y_test = tf.keras.utils.to_categorical(y_test, num_classes) "],"execution_count":4,"outputs":[{"output_type":"stream","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170500096/170498071 [==============================] - 4s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"3lAk_Mw_5-rn","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1597104086859,"user_tz":-330,"elapsed":8929,"user":{"displayName":"Kumar Shwetaketu","photoUrl":"","userId":"02755040458660561297"}},"outputId":"ef7ad163-5d97-4415-e8af-cc2361b7da75"},"source":["X_train.shape"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(50000, 32, 32, 3)"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"DVkpgHsc5-rp","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1597104086862,"user_tz":-330,"elapsed":8917,"user":{"displayName":"Kumar Shwetaketu","photoUrl":"","userId":"02755040458660561297"}},"outputId":"2dc981a8-4853-4c66-cb27-cfb03ce1e202"},"source":["X_test.shape"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10000, 32, 32, 3)"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ee-sge5Kg7vr","colab":{},"executionInfo":{"status":"ok","timestamp":1597104086864,"user_tz":-330,"elapsed":8913,"user":{"displayName":"Kumar Shwetaketu","photoUrl":"","userId":"02755040458660561297"}}},"source":["# Dense Block\n","def denseblock(input, num_filter = 12, dropout_rate = 0.2):\n","    global compression\n","    temp = input\n","    for _ in range(l): \n","        BatchNorm = layers.BatchNormalization()(temp)\n","        relu = layers.Activation('relu')(BatchNorm)\n","        Conv2D_3_3 = layers.Conv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same')(relu)\n","\n","        # Removing the dropout layer as per requirement.\n","        #if dropout_rate>0:\n","        #    Conv2D_3_3 = layers.Dropout(dropout_rate)(Conv2D_3_3)\n","\n","        concat = layers.Concatenate(axis=-1)([temp,Conv2D_3_3])\n","        \n","        temp = concat\n","        \n","    return temp\n","\n","## transition Blosck\n","def transition(input, num_filter = 12, dropout_rate = 0.2):\n","    global compression\n","    BatchNorm = layers.BatchNormalization()(input)\n","    relu = layers.Activation('relu')(BatchNorm)\n","    Conv2D_BottleNeck = layers.Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n","\n","    # Removing the dropout layer as per requirement.\n","    #if dropout_rate>0:\n","    #     Conv2D_BottleNeck = layers.Dropout(dropout_rate)(Conv2D_BottleNeck)\n","    \n","    avg = layers.AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n","    return avg\n","\n","#output layer\n","def output_layer(input):\n","    global compression\n","    BatchNorm = layers.BatchNormalization()(input)\n","    relu = layers.Activation('relu')(BatchNorm)\n","    AvgPooling = layers.AveragePooling2D(pool_size=(2,2))(relu)\n","    new_layer = layers.Conv2D(num_classes, kernel_size = (2,2))(AvgPooling)\n","    output = Activation('softmax')(new_layer)\n","    flat = Flatten()(output)\n","    return flat"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"anPCpQWhhGb7","colab":{},"executionInfo":{"status":"ok","timestamp":1597104093078,"user_tz":-330,"elapsed":15120,"user":{"displayName":"Kumar Shwetaketu","photoUrl":"","userId":"02755040458660561297"}}},"source":["## increasing the number of filters\n","num_filter = 24\n","\n","##Dropout is commenented. paramter doesnt affect anything\n","dropout_rate = 0.2\n","l = 12\n","input = layers.Input(shape=(img_height, img_width, channel,))\n","First_Conv2D = layers.Conv2D(num_filter, (3,3), use_bias=False ,padding='same')(input)\n","\n","First_Block = denseblock(First_Conv2D, num_filter, dropout_rate)\n","First_Transition = transition(First_Block, num_filter, dropout_rate)\n","\n","Second_Block = denseblock(First_Transition, num_filter, dropout_rate)\n","Second_Transition = transition(Second_Block, num_filter, dropout_rate)\n","\n","Third_Block = denseblock(Second_Transition, num_filter, dropout_rate)\n","Third_Transition = transition(Third_Block, num_filter, dropout_rate)\n","\n","Last_Block = denseblock(Third_Transition,  num_filter, dropout_rate)\n","output = output_layer(Last_Block)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"c5Wksy8z5-rw","colab":{"base_uri":"https://localhost:8080/","height":321},"executionInfo":{"status":"ok","timestamp":1597104093079,"user_tz":-330,"elapsed":15096,"user":{"displayName":"Kumar Shwetaketu","photoUrl":"","userId":"02755040458660561297"}},"outputId":"bbd282e0-210c-48f3-c9a4-54e7d00543e5"},"source":["#https://arxiv.org/pdf/1608.06993.pdf\n","from IPython.display import IFrame, YouTubeVideo\n","YouTubeVideo(id='-W6y8xnd--U', width=600)"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","        <iframe\n","            width=\"600\"\n","            height=\"300\"\n","            src=\"https://www.youtube.com/embed/-W6y8xnd--U\"\n","            frameborder=\"0\"\n","            allowfullscreen\n","        ></iframe>\n","        "],"text/plain":["<IPython.lib.display.YouTubeVideo at 0x7f8a3ee574a8>"],"image/jpeg":"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\n"},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"1kFh7pdxhNtT","scrolled":true,"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1597104093080,"user_tz":-330,"elapsed":15079,"user":{"displayName":"Kumar Shwetaketu","photoUrl":"","userId":"02755040458660561297"}},"outputId":"bd531148-bfed-4513-f24e-53232ef7d3c9"},"source":["model = Model(inputs=[input], outputs=[output])\n","model.summary()"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Model: \"functional_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 32, 32, 24)   648         input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 32, 32, 24)   96          conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","activation (Activation)         (None, 32, 32, 24)   0           batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 32, 32, 12)   2592        activation[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 32, 32, 36)   0           conv2d[0][0]                     \n","                                                                 conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 32, 32, 36)   144         concatenate[0][0]                \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 32, 32, 36)   0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 32, 32, 12)   3888        activation_1[0][0]               \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 32, 32, 48)   0           concatenate[0][0]                \n","                                                                 conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 32, 32, 48)   192         concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 32, 32, 48)   0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 32, 32, 12)   5184        activation_2[0][0]               \n","__________________________________________________________________________________________________\n","concatenate_2 (Concatenate)     (None, 32, 32, 60)   0           concatenate_1[0][0]              \n","                                                                 conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 32, 32, 60)   240         concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 32, 32, 60)   0           batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 32, 32, 12)   6480        activation_3[0][0]               \n","__________________________________________________________________________________________________\n","concatenate_3 (Concatenate)     (None, 32, 32, 72)   0           concatenate_2[0][0]              \n","                                                                 conv2d_4[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 32, 32, 72)   288         concatenate_3[0][0]              \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 32, 32, 72)   0           batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 32, 32, 12)   7776        activation_4[0][0]               \n","__________________________________________________________________________________________________\n","concatenate_4 (Concatenate)     (None, 32, 32, 84)   0           concatenate_3[0][0]              \n","                                                                 conv2d_5[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_5 (BatchNor (None, 32, 32, 84)   336         concatenate_4[0][0]              \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 32, 32, 84)   0           batch_normalization_5[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 32, 32, 12)   9072        activation_5[0][0]               \n","__________________________________________________________________________________________________\n","concatenate_5 (Concatenate)     (None, 32, 32, 96)   0           concatenate_4[0][0]              \n","                                                                 conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_6 (BatchNor (None, 32, 32, 96)   384         concatenate_5[0][0]              \n","__________________________________________________________________________________________________\n","activation_6 (Activation)       (None, 32, 32, 96)   0           batch_normalization_6[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 32, 32, 12)   10368       activation_6[0][0]               \n","__________________________________________________________________________________________________\n","concatenate_6 (Concatenate)     (None, 32, 32, 108)  0           concatenate_5[0][0]              \n","                                                                 conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_7 (BatchNor (None, 32, 32, 108)  432         concatenate_6[0][0]              \n","__________________________________________________________________________________________________\n","activation_7 (Activation)       (None, 32, 32, 108)  0           batch_normalization_7[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 32, 32, 12)   11664       activation_7[0][0]               \n","__________________________________________________________________________________________________\n","concatenate_7 (Concatenate)     (None, 32, 32, 120)  0           concatenate_6[0][0]              \n","                                                                 conv2d_8[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_8 (BatchNor (None, 32, 32, 120)  480         concatenate_7[0][0]              \n","__________________________________________________________________________________________________\n","activation_8 (Activation)       (None, 32, 32, 120)  0           batch_normalization_8[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 32, 32, 12)   12960       activation_8[0][0]               \n","__________________________________________________________________________________________________\n","concatenate_8 (Concatenate)     (None, 32, 32, 132)  0           concatenate_7[0][0]              \n","                                                                 conv2d_9[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_9 (BatchNor (None, 32, 32, 132)  528         concatenate_8[0][0]              \n","__________________________________________________________________________________________________\n","activation_9 (Activation)       (None, 32, 32, 132)  0           batch_normalization_9[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 32, 32, 12)   14256       activation_9[0][0]               \n","__________________________________________________________________________________________________\n","concatenate_9 (Concatenate)     (None, 32, 32, 144)  0           concatenate_8[0][0]              \n","                                                                 conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_10 (BatchNo (None, 32, 32, 144)  576         concatenate_9[0][0]              \n","__________________________________________________________________________________________________\n","activation_10 (Activation)      (None, 32, 32, 144)  0           batch_normalization_10[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 32, 32, 12)   15552       activation_10[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_10 (Concatenate)    (None, 32, 32, 156)  0           concatenate_9[0][0]              \n","                                                                 conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_11 (BatchNo (None, 32, 32, 156)  624         concatenate_10[0][0]             \n","__________________________________________________________________________________________________\n","activation_11 (Activation)      (None, 32, 32, 156)  0           batch_normalization_11[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 32, 32, 12)   16848       activation_11[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_11 (Concatenate)    (None, 32, 32, 168)  0           concatenate_10[0][0]             \n","                                                                 conv2d_12[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_12 (BatchNo (None, 32, 32, 168)  672         concatenate_11[0][0]             \n","__________________________________________________________________________________________________\n","activation_12 (Activation)      (None, 32, 32, 168)  0           batch_normalization_12[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 32, 32, 12)   2016        activation_12[0][0]              \n","__________________________________________________________________________________________________\n","average_pooling2d (AveragePooli (None, 16, 16, 12)   0           conv2d_13[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_13 (BatchNo (None, 16, 16, 12)   48          average_pooling2d[0][0]          \n","__________________________________________________________________________________________________\n","activation_13 (Activation)      (None, 16, 16, 12)   0           batch_normalization_13[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 16, 16, 12)   1296        activation_13[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_12 (Concatenate)    (None, 16, 16, 24)   0           average_pooling2d[0][0]          \n","                                                                 conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_14 (BatchNo (None, 16, 16, 24)   96          concatenate_12[0][0]             \n","__________________________________________________________________________________________________\n","activation_14 (Activation)      (None, 16, 16, 24)   0           batch_normalization_14[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 16, 16, 12)   2592        activation_14[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_13 (Concatenate)    (None, 16, 16, 36)   0           concatenate_12[0][0]             \n","                                                                 conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_15 (BatchNo (None, 16, 16, 36)   144         concatenate_13[0][0]             \n","__________________________________________________________________________________________________\n","activation_15 (Activation)      (None, 16, 16, 36)   0           batch_normalization_15[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_16 (Conv2D)              (None, 16, 16, 12)   3888        activation_15[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_14 (Concatenate)    (None, 16, 16, 48)   0           concatenate_13[0][0]             \n","                                                                 conv2d_16[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_16 (BatchNo (None, 16, 16, 48)   192         concatenate_14[0][0]             \n","__________________________________________________________________________________________________\n","activation_16 (Activation)      (None, 16, 16, 48)   0           batch_normalization_16[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_17 (Conv2D)              (None, 16, 16, 12)   5184        activation_16[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_15 (Concatenate)    (None, 16, 16, 60)   0           concatenate_14[0][0]             \n","                                                                 conv2d_17[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_17 (BatchNo (None, 16, 16, 60)   240         concatenate_15[0][0]             \n","__________________________________________________________________________________________________\n","activation_17 (Activation)      (None, 16, 16, 60)   0           batch_normalization_17[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_18 (Conv2D)              (None, 16, 16, 12)   6480        activation_17[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_16 (Concatenate)    (None, 16, 16, 72)   0           concatenate_15[0][0]             \n","                                                                 conv2d_18[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_18 (BatchNo (None, 16, 16, 72)   288         concatenate_16[0][0]             \n","__________________________________________________________________________________________________\n","activation_18 (Activation)      (None, 16, 16, 72)   0           batch_normalization_18[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_19 (Conv2D)              (None, 16, 16, 12)   7776        activation_18[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_17 (Concatenate)    (None, 16, 16, 84)   0           concatenate_16[0][0]             \n","                                                                 conv2d_19[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_19 (BatchNo (None, 16, 16, 84)   336         concatenate_17[0][0]             \n","__________________________________________________________________________________________________\n","activation_19 (Activation)      (None, 16, 16, 84)   0           batch_normalization_19[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_20 (Conv2D)              (None, 16, 16, 12)   9072        activation_19[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_18 (Concatenate)    (None, 16, 16, 96)   0           concatenate_17[0][0]             \n","                                                                 conv2d_20[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_20 (BatchNo (None, 16, 16, 96)   384         concatenate_18[0][0]             \n","__________________________________________________________________________________________________\n","activation_20 (Activation)      (None, 16, 16, 96)   0           batch_normalization_20[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_21 (Conv2D)              (None, 16, 16, 12)   10368       activation_20[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_19 (Concatenate)    (None, 16, 16, 108)  0           concatenate_18[0][0]             \n","                                                                 conv2d_21[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_21 (BatchNo (None, 16, 16, 108)  432         concatenate_19[0][0]             \n","__________________________________________________________________________________________________\n","activation_21 (Activation)      (None, 16, 16, 108)  0           batch_normalization_21[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_22 (Conv2D)              (None, 16, 16, 12)   11664       activation_21[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_20 (Concatenate)    (None, 16, 16, 120)  0           concatenate_19[0][0]             \n","                                                                 conv2d_22[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_22 (BatchNo (None, 16, 16, 120)  480         concatenate_20[0][0]             \n","__________________________________________________________________________________________________\n","activation_22 (Activation)      (None, 16, 16, 120)  0           batch_normalization_22[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_23 (Conv2D)              (None, 16, 16, 12)   12960       activation_22[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_21 (Concatenate)    (None, 16, 16, 132)  0           concatenate_20[0][0]             \n","                                                                 conv2d_23[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_23 (BatchNo (None, 16, 16, 132)  528         concatenate_21[0][0]             \n","__________________________________________________________________________________________________\n","activation_23 (Activation)      (None, 16, 16, 132)  0           batch_normalization_23[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_24 (Conv2D)              (None, 16, 16, 12)   14256       activation_23[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_22 (Concatenate)    (None, 16, 16, 144)  0           concatenate_21[0][0]             \n","                                                                 conv2d_24[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_24 (BatchNo (None, 16, 16, 144)  576         concatenate_22[0][0]             \n","__________________________________________________________________________________________________\n","activation_24 (Activation)      (None, 16, 16, 144)  0           batch_normalization_24[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_25 (Conv2D)              (None, 16, 16, 12)   15552       activation_24[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_23 (Concatenate)    (None, 16, 16, 156)  0           concatenate_22[0][0]             \n","                                                                 conv2d_25[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_25 (BatchNo (None, 16, 16, 156)  624         concatenate_23[0][0]             \n","__________________________________________________________________________________________________\n","activation_25 (Activation)      (None, 16, 16, 156)  0           batch_normalization_25[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_26 (Conv2D)              (None, 16, 16, 12)   1872        activation_25[0][0]              \n","__________________________________________________________________________________________________\n","average_pooling2d_1 (AveragePoo (None, 8, 8, 12)     0           conv2d_26[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_26 (BatchNo (None, 8, 8, 12)     48          average_pooling2d_1[0][0]        \n","__________________________________________________________________________________________________\n","activation_26 (Activation)      (None, 8, 8, 12)     0           batch_normalization_26[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_27 (Conv2D)              (None, 8, 8, 12)     1296        activation_26[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_24 (Concatenate)    (None, 8, 8, 24)     0           average_pooling2d_1[0][0]        \n","                                                                 conv2d_27[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_27 (BatchNo (None, 8, 8, 24)     96          concatenate_24[0][0]             \n","__________________________________________________________________________________________________\n","activation_27 (Activation)      (None, 8, 8, 24)     0           batch_normalization_27[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_28 (Conv2D)              (None, 8, 8, 12)     2592        activation_27[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_25 (Concatenate)    (None, 8, 8, 36)     0           concatenate_24[0][0]             \n","                                                                 conv2d_28[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_28 (BatchNo (None, 8, 8, 36)     144         concatenate_25[0][0]             \n","__________________________________________________________________________________________________\n","activation_28 (Activation)      (None, 8, 8, 36)     0           batch_normalization_28[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_29 (Conv2D)              (None, 8, 8, 12)     3888        activation_28[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_26 (Concatenate)    (None, 8, 8, 48)     0           concatenate_25[0][0]             \n","                                                                 conv2d_29[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_29 (BatchNo (None, 8, 8, 48)     192         concatenate_26[0][0]             \n","__________________________________________________________________________________________________\n","activation_29 (Activation)      (None, 8, 8, 48)     0           batch_normalization_29[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_30 (Conv2D)              (None, 8, 8, 12)     5184        activation_29[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_27 (Concatenate)    (None, 8, 8, 60)     0           concatenate_26[0][0]             \n","                                                                 conv2d_30[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_30 (BatchNo (None, 8, 8, 60)     240         concatenate_27[0][0]             \n","__________________________________________________________________________________________________\n","activation_30 (Activation)      (None, 8, 8, 60)     0           batch_normalization_30[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_31 (Conv2D)              (None, 8, 8, 12)     6480        activation_30[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_28 (Concatenate)    (None, 8, 8, 72)     0           concatenate_27[0][0]             \n","                                                                 conv2d_31[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_31 (BatchNo (None, 8, 8, 72)     288         concatenate_28[0][0]             \n","__________________________________________________________________________________________________\n","activation_31 (Activation)      (None, 8, 8, 72)     0           batch_normalization_31[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_32 (Conv2D)              (None, 8, 8, 12)     7776        activation_31[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_29 (Concatenate)    (None, 8, 8, 84)     0           concatenate_28[0][0]             \n","                                                                 conv2d_32[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_32 (BatchNo (None, 8, 8, 84)     336         concatenate_29[0][0]             \n","__________________________________________________________________________________________________\n","activation_32 (Activation)      (None, 8, 8, 84)     0           batch_normalization_32[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_33 (Conv2D)              (None, 8, 8, 12)     9072        activation_32[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_30 (Concatenate)    (None, 8, 8, 96)     0           concatenate_29[0][0]             \n","                                                                 conv2d_33[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_33 (BatchNo (None, 8, 8, 96)     384         concatenate_30[0][0]             \n","__________________________________________________________________________________________________\n","activation_33 (Activation)      (None, 8, 8, 96)     0           batch_normalization_33[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_34 (Conv2D)              (None, 8, 8, 12)     10368       activation_33[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_31 (Concatenate)    (None, 8, 8, 108)    0           concatenate_30[0][0]             \n","                                                                 conv2d_34[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_34 (BatchNo (None, 8, 8, 108)    432         concatenate_31[0][0]             \n","__________________________________________________________________________________________________\n","activation_34 (Activation)      (None, 8, 8, 108)    0           batch_normalization_34[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_35 (Conv2D)              (None, 8, 8, 12)     11664       activation_34[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_32 (Concatenate)    (None, 8, 8, 120)    0           concatenate_31[0][0]             \n","                                                                 conv2d_35[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_35 (BatchNo (None, 8, 8, 120)    480         concatenate_32[0][0]             \n","__________________________________________________________________________________________________\n","activation_35 (Activation)      (None, 8, 8, 120)    0           batch_normalization_35[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_36 (Conv2D)              (None, 8, 8, 12)     12960       activation_35[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_33 (Concatenate)    (None, 8, 8, 132)    0           concatenate_32[0][0]             \n","                                                                 conv2d_36[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_36 (BatchNo (None, 8, 8, 132)    528         concatenate_33[0][0]             \n","__________________________________________________________________________________________________\n","activation_36 (Activation)      (None, 8, 8, 132)    0           batch_normalization_36[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_37 (Conv2D)              (None, 8, 8, 12)     14256       activation_36[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_34 (Concatenate)    (None, 8, 8, 144)    0           concatenate_33[0][0]             \n","                                                                 conv2d_37[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_37 (BatchNo (None, 8, 8, 144)    576         concatenate_34[0][0]             \n","__________________________________________________________________________________________________\n","activation_37 (Activation)      (None, 8, 8, 144)    0           batch_normalization_37[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_38 (Conv2D)              (None, 8, 8, 12)     15552       activation_37[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_35 (Concatenate)    (None, 8, 8, 156)    0           concatenate_34[0][0]             \n","                                                                 conv2d_38[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_38 (BatchNo (None, 8, 8, 156)    624         concatenate_35[0][0]             \n","__________________________________________________________________________________________________\n","activation_38 (Activation)      (None, 8, 8, 156)    0           batch_normalization_38[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_39 (Conv2D)              (None, 8, 8, 12)     1872        activation_38[0][0]              \n","__________________________________________________________________________________________________\n","average_pooling2d_2 (AveragePoo (None, 4, 4, 12)     0           conv2d_39[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_39 (BatchNo (None, 4, 4, 12)     48          average_pooling2d_2[0][0]        \n","__________________________________________________________________________________________________\n","activation_39 (Activation)      (None, 4, 4, 12)     0           batch_normalization_39[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_40 (Conv2D)              (None, 4, 4, 12)     1296        activation_39[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_36 (Concatenate)    (None, 4, 4, 24)     0           average_pooling2d_2[0][0]        \n","                                                                 conv2d_40[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_40 (BatchNo (None, 4, 4, 24)     96          concatenate_36[0][0]             \n","__________________________________________________________________________________________________\n","activation_40 (Activation)      (None, 4, 4, 24)     0           batch_normalization_40[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_41 (Conv2D)              (None, 4, 4, 12)     2592        activation_40[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_37 (Concatenate)    (None, 4, 4, 36)     0           concatenate_36[0][0]             \n","                                                                 conv2d_41[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_41 (BatchNo (None, 4, 4, 36)     144         concatenate_37[0][0]             \n","__________________________________________________________________________________________________\n","activation_41 (Activation)      (None, 4, 4, 36)     0           batch_normalization_41[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_42 (Conv2D)              (None, 4, 4, 12)     3888        activation_41[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_38 (Concatenate)    (None, 4, 4, 48)     0           concatenate_37[0][0]             \n","                                                                 conv2d_42[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_42 (BatchNo (None, 4, 4, 48)     192         concatenate_38[0][0]             \n","__________________________________________________________________________________________________\n","activation_42 (Activation)      (None, 4, 4, 48)     0           batch_normalization_42[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_43 (Conv2D)              (None, 4, 4, 12)     5184        activation_42[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_39 (Concatenate)    (None, 4, 4, 60)     0           concatenate_38[0][0]             \n","                                                                 conv2d_43[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_43 (BatchNo (None, 4, 4, 60)     240         concatenate_39[0][0]             \n","__________________________________________________________________________________________________\n","activation_43 (Activation)      (None, 4, 4, 60)     0           batch_normalization_43[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_44 (Conv2D)              (None, 4, 4, 12)     6480        activation_43[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_40 (Concatenate)    (None, 4, 4, 72)     0           concatenate_39[0][0]             \n","                                                                 conv2d_44[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_44 (BatchNo (None, 4, 4, 72)     288         concatenate_40[0][0]             \n","__________________________________________________________________________________________________\n","activation_44 (Activation)      (None, 4, 4, 72)     0           batch_normalization_44[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_45 (Conv2D)              (None, 4, 4, 12)     7776        activation_44[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_41 (Concatenate)    (None, 4, 4, 84)     0           concatenate_40[0][0]             \n","                                                                 conv2d_45[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_45 (BatchNo (None, 4, 4, 84)     336         concatenate_41[0][0]             \n","__________________________________________________________________________________________________\n","activation_45 (Activation)      (None, 4, 4, 84)     0           batch_normalization_45[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_46 (Conv2D)              (None, 4, 4, 12)     9072        activation_45[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_42 (Concatenate)    (None, 4, 4, 96)     0           concatenate_41[0][0]             \n","                                                                 conv2d_46[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_46 (BatchNo (None, 4, 4, 96)     384         concatenate_42[0][0]             \n","__________________________________________________________________________________________________\n","activation_46 (Activation)      (None, 4, 4, 96)     0           batch_normalization_46[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_47 (Conv2D)              (None, 4, 4, 12)     10368       activation_46[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_43 (Concatenate)    (None, 4, 4, 108)    0           concatenate_42[0][0]             \n","                                                                 conv2d_47[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_47 (BatchNo (None, 4, 4, 108)    432         concatenate_43[0][0]             \n","__________________________________________________________________________________________________\n","activation_47 (Activation)      (None, 4, 4, 108)    0           batch_normalization_47[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_48 (Conv2D)              (None, 4, 4, 12)     11664       activation_47[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_44 (Concatenate)    (None, 4, 4, 120)    0           concatenate_43[0][0]             \n","                                                                 conv2d_48[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_48 (BatchNo (None, 4, 4, 120)    480         concatenate_44[0][0]             \n","__________________________________________________________________________________________________\n","activation_48 (Activation)      (None, 4, 4, 120)    0           batch_normalization_48[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_49 (Conv2D)              (None, 4, 4, 12)     12960       activation_48[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_45 (Concatenate)    (None, 4, 4, 132)    0           concatenate_44[0][0]             \n","                                                                 conv2d_49[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_49 (BatchNo (None, 4, 4, 132)    528         concatenate_45[0][0]             \n","__________________________________________________________________________________________________\n","activation_49 (Activation)      (None, 4, 4, 132)    0           batch_normalization_49[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_50 (Conv2D)              (None, 4, 4, 12)     14256       activation_49[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_46 (Concatenate)    (None, 4, 4, 144)    0           concatenate_45[0][0]             \n","                                                                 conv2d_50[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_50 (BatchNo (None, 4, 4, 144)    576         concatenate_46[0][0]             \n","__________________________________________________________________________________________________\n","activation_50 (Activation)      (None, 4, 4, 144)    0           batch_normalization_50[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_51 (Conv2D)              (None, 4, 4, 12)     15552       activation_50[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_47 (Concatenate)    (None, 4, 4, 156)    0           concatenate_46[0][0]             \n","                                                                 conv2d_51[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_51 (BatchNo (None, 4, 4, 156)    624         concatenate_47[0][0]             \n","__________________________________________________________________________________________________\n","activation_51 (Activation)      (None, 4, 4, 156)    0           batch_normalization_51[0][0]     \n","__________________________________________________________________________________________________\n","average_pooling2d_3 (AveragePoo (None, 2, 2, 156)    0           activation_51[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_52 (Conv2D)              (None, 1, 1, 10)     6250        average_pooling2d_3[0][0]        \n","__________________________________________________________________________________________________\n","activation_52 (Activation)      (None, 1, 1, 10)     0           conv2d_52[0][0]                  \n","__________________________________________________________________________________________________\n","flatten (Flatten)               (None, 10)           0           activation_52[0][0]              \n","==================================================================================================\n","Total params: 450,658\n","Trainable params: 441,610\n","Non-trainable params: 9,048\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kyqx6LVMzfpL","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597104094667,"user_tz":-330,"elapsed":16661,"user":{"displayName":"Kumar Shwetaketu","photoUrl":"","userId":"02755040458660561297"}}},"source":["## Addition Image augmentation\n","from keras.preprocessing.image import ImageDataGenerator\n","datagen = ImageDataGenerator(rotation_range = 15, horizontal_flip = True, width_shift_range = 0.1, height_shift_range = 0.1, zoom_range = 0.2, shear_range = 15)\n","datagen.fit(X_train)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"b4XOsW3ahSkL","colab":{},"executionInfo":{"status":"ok","timestamp":1597104094674,"user_tz":-330,"elapsed":16664,"user":{"displayName":"Kumar Shwetaketu","photoUrl":"","userId":"02755040458660561297"}}},"source":["# determine Loss function and Optimizer\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=Adam(),\n","              metrics=['accuracy'])\n","\n"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"99U0JWDr0w5H","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1597107488859,"user_tz":-330,"elapsed":3410837,"user":{"displayName":"Kumar Shwetaketu","photoUrl":"","userId":"02755040458660561297"}},"outputId":"b6032684-4a5b-47f1-8aa6-eff5bafa7ff6"},"source":["## Train for first 50 epochs\n","model.fit_generator(datagen.flow(X_train, y_train, batch_size), steps_per_epoch = X_train.shape[0]/batch_size, epochs = 50, validation_data =(X_test, y_test))"],"execution_count":13,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-13-631b63ec3055>:2: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use Model.fit, which supports generators.\n","Epoch 1/50\n","391/390 [==============================] - 67s 173ms/step - loss: 1.5796 - accuracy: 0.4196 - val_loss: 2.3397 - val_accuracy: 0.3457\n","Epoch 2/50\n","391/390 [==============================] - 66s 169ms/step - loss: 1.2372 - accuracy: 0.5512 - val_loss: 1.7781 - val_accuracy: 0.4764\n","Epoch 3/50\n","391/390 [==============================] - 67s 171ms/step - loss: 1.0696 - accuracy: 0.6180 - val_loss: 1.1352 - val_accuracy: 0.6151\n","Epoch 4/50\n","391/390 [==============================] - 67s 172ms/step - loss: 0.9627 - accuracy: 0.6567 - val_loss: 1.0799 - val_accuracy: 0.6372\n","Epoch 5/50\n","391/390 [==============================] - 68s 173ms/step - loss: 0.8757 - accuracy: 0.6882 - val_loss: 0.8724 - val_accuracy: 0.6952\n","Epoch 6/50\n","391/390 [==============================] - 68s 173ms/step - loss: 0.8119 - accuracy: 0.7139 - val_loss: 1.3121 - val_accuracy: 0.6158\n","Epoch 7/50\n","391/390 [==============================] - 68s 173ms/step - loss: 0.7707 - accuracy: 0.7294 - val_loss: 0.7677 - val_accuracy: 0.7280\n","Epoch 8/50\n","391/390 [==============================] - 68s 173ms/step - loss: 0.7263 - accuracy: 0.7465 - val_loss: 0.9272 - val_accuracy: 0.7021\n","Epoch 9/50\n","391/390 [==============================] - 68s 173ms/step - loss: 0.6923 - accuracy: 0.7578 - val_loss: 1.2124 - val_accuracy: 0.6310\n","Epoch 10/50\n","391/390 [==============================] - 68s 173ms/step - loss: 0.6644 - accuracy: 0.7668 - val_loss: 0.7713 - val_accuracy: 0.7432\n","Epoch 11/50\n","391/390 [==============================] - 68s 173ms/step - loss: 0.6410 - accuracy: 0.7771 - val_loss: 0.9435 - val_accuracy: 0.7054\n","Epoch 12/50\n","391/390 [==============================] - 68s 173ms/step - loss: 0.6122 - accuracy: 0.7878 - val_loss: 0.7526 - val_accuracy: 0.7577\n","Epoch 13/50\n","391/390 [==============================] - 68s 173ms/step - loss: 0.5867 - accuracy: 0.7976 - val_loss: 0.6086 - val_accuracy: 0.7994\n","Epoch 14/50\n","391/390 [==============================] - 68s 173ms/step - loss: 0.5708 - accuracy: 0.8002 - val_loss: 0.7050 - val_accuracy: 0.7681\n","Epoch 15/50\n","391/390 [==============================] - 68s 173ms/step - loss: 0.5523 - accuracy: 0.8066 - val_loss: 0.7161 - val_accuracy: 0.7784\n","Epoch 16/50\n","391/390 [==============================] - 68s 173ms/step - loss: 0.5422 - accuracy: 0.8107 - val_loss: 0.6709 - val_accuracy: 0.7832\n","Epoch 17/50\n","391/390 [==============================] - 68s 173ms/step - loss: 0.5206 - accuracy: 0.8198 - val_loss: 0.7262 - val_accuracy: 0.7727\n","Epoch 18/50\n","391/390 [==============================] - 68s 173ms/step - loss: 0.5069 - accuracy: 0.8232 - val_loss: 0.7838 - val_accuracy: 0.7570\n","Epoch 19/50\n","391/390 [==============================] - 68s 173ms/step - loss: 0.4964 - accuracy: 0.8275 - val_loss: 0.5345 - val_accuracy: 0.8230\n","Epoch 20/50\n","391/390 [==============================] - 67s 173ms/step - loss: 0.4838 - accuracy: 0.8308 - val_loss: 0.5440 - val_accuracy: 0.8124\n","Epoch 21/50\n","391/390 [==============================] - 68s 173ms/step - loss: 0.4721 - accuracy: 0.8359 - val_loss: 0.5161 - val_accuracy: 0.8311\n","Epoch 22/50\n","391/390 [==============================] - 68s 173ms/step - loss: 0.4667 - accuracy: 0.8376 - val_loss: 0.6060 - val_accuracy: 0.7974\n","Epoch 23/50\n","391/390 [==============================] - 68s 173ms/step - loss: 0.4500 - accuracy: 0.8443 - val_loss: 0.6533 - val_accuracy: 0.7993\n","Epoch 24/50\n","391/390 [==============================] - 68s 173ms/step - loss: 0.4371 - accuracy: 0.8494 - val_loss: 0.4500 - val_accuracy: 0.8492\n","Epoch 25/50\n","391/390 [==============================] - 68s 173ms/step - loss: 0.4289 - accuracy: 0.8515 - val_loss: 0.4795 - val_accuracy: 0.8365\n","Epoch 26/50\n","391/390 [==============================] - 67s 173ms/step - loss: 0.4214 - accuracy: 0.8526 - val_loss: 0.5931 - val_accuracy: 0.8160\n","Epoch 27/50\n","391/390 [==============================] - 68s 173ms/step - loss: 0.4121 - accuracy: 0.8569 - val_loss: 0.4930 - val_accuracy: 0.8358\n","Epoch 28/50\n","391/390 [==============================] - 68s 173ms/step - loss: 0.4090 - accuracy: 0.8582 - val_loss: 0.4845 - val_accuracy: 0.8381\n","Epoch 29/50\n","391/390 [==============================] - 68s 173ms/step - loss: 0.3995 - accuracy: 0.8618 - val_loss: 0.8231 - val_accuracy: 0.7682\n","Epoch 30/50\n","391/390 [==============================] - 68s 173ms/step - loss: 0.3939 - accuracy: 0.8621 - val_loss: 0.6094 - val_accuracy: 0.8122\n","Epoch 31/50\n","391/390 [==============================] - 67s 173ms/step - loss: 0.3837 - accuracy: 0.8656 - val_loss: 0.4552 - val_accuracy: 0.8464\n","Epoch 32/50\n","391/390 [==============================] - 68s 173ms/step - loss: 0.3815 - accuracy: 0.8675 - val_loss: 0.6744 - val_accuracy: 0.7985\n","Epoch 33/50\n","391/390 [==============================] - 67s 173ms/step - loss: 0.3722 - accuracy: 0.8704 - val_loss: 0.6307 - val_accuracy: 0.8101\n","Epoch 34/50\n","391/390 [==============================] - 68s 173ms/step - loss: 0.3691 - accuracy: 0.8721 - val_loss: 0.4889 - val_accuracy: 0.8447\n","Epoch 35/50\n","391/390 [==============================] - 67s 172ms/step - loss: 0.3632 - accuracy: 0.8728 - val_loss: 0.5070 - val_accuracy: 0.8383\n","Epoch 36/50\n","391/390 [==============================] - 68s 173ms/step - loss: 0.3559 - accuracy: 0.8759 - val_loss: 0.4441 - val_accuracy: 0.8537\n","Epoch 37/50\n","391/390 [==============================] - 67s 173ms/step - loss: 0.3535 - accuracy: 0.8756 - val_loss: 0.5205 - val_accuracy: 0.8378\n","Epoch 38/50\n","391/390 [==============================] - 67s 173ms/step - loss: 0.3486 - accuracy: 0.8769 - val_loss: 0.5530 - val_accuracy: 0.8305\n","Epoch 39/50\n","391/390 [==============================] - 68s 173ms/step - loss: 0.3464 - accuracy: 0.8803 - val_loss: 0.5760 - val_accuracy: 0.8243\n","Epoch 40/50\n","391/390 [==============================] - 68s 173ms/step - loss: 0.3371 - accuracy: 0.8821 - val_loss: 0.5161 - val_accuracy: 0.8316\n","Epoch 41/50\n","391/390 [==============================] - 67s 173ms/step - loss: 0.3309 - accuracy: 0.8871 - val_loss: 0.5372 - val_accuracy: 0.8399\n","Epoch 42/50\n","391/390 [==============================] - 67s 173ms/step - loss: 0.3294 - accuracy: 0.8854 - val_loss: 0.5169 - val_accuracy: 0.8386\n","Epoch 43/50\n","391/390 [==============================] - 68s 173ms/step - loss: 0.3254 - accuracy: 0.8854 - val_loss: 0.4947 - val_accuracy: 0.8440\n","Epoch 44/50\n","391/390 [==============================] - 68s 173ms/step - loss: 0.3221 - accuracy: 0.8880 - val_loss: 0.6237 - val_accuracy: 0.8143\n","Epoch 45/50\n","391/390 [==============================] - 67s 173ms/step - loss: 0.3191 - accuracy: 0.8884 - val_loss: 0.4035 - val_accuracy: 0.8692\n","Epoch 46/50\n","391/390 [==============================] - 68s 173ms/step - loss: 0.3068 - accuracy: 0.8922 - val_loss: 0.5304 - val_accuracy: 0.8438\n","Epoch 47/50\n","391/390 [==============================] - 67s 172ms/step - loss: 0.3093 - accuracy: 0.8928 - val_loss: 0.6922 - val_accuracy: 0.7999\n","Epoch 48/50\n","391/390 [==============================] - 67s 173ms/step - loss: 0.3069 - accuracy: 0.8953 - val_loss: 0.4894 - val_accuracy: 0.8484\n","Epoch 49/50\n","391/390 [==============================] - 68s 173ms/step - loss: 0.2978 - accuracy: 0.8950 - val_loss: 0.4001 - val_accuracy: 0.8681\n","Epoch 50/50\n","391/390 [==============================] - 68s 173ms/step - loss: 0.2938 - accuracy: 0.8965 - val_loss: 0.4212 - val_accuracy: 0.8658\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f89d2e8c9e8>"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ZcWydmIVhZGr","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1597107492012,"user_tz":-330,"elapsed":3413976,"user":{"displayName":"Kumar Shwetaketu","photoUrl":"","userId":"02755040458660561297"}},"outputId":"4bef9357-372c-4843-ee8d-e988a9274497"},"source":["# Test the model\n","\n","\n","model.evaluate(X_test, y_test)\n"," "],"execution_count":14,"outputs":[{"output_type":"stream","text":["313/313 [==============================] - 3s 11ms/step - loss: 0.4212 - accuracy: 0.8658\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[0.4212377071380615, 0.8658000230789185]"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"UE3lF6EH1r_L","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1597107492587,"user_tz":-330,"elapsed":3414538,"user":{"displayName":"Kumar Shwetaketu","photoUrl":"","userId":"02755040458660561297"}},"outputId":"6d7b10ad-7296-438d-d51c-d1bec8acee56"},"source":["# Save the trained weights in to .h5 format\n","model.save_weights(\"DNST_model.h5\")\n","print(\"Saved model to disk\")"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Saved model to disk\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jv4put7zBPY-","colab_type":"text"},"source":[" Adding 5 more epochs to get further accuracy"]},{"cell_type":"code","metadata":{"id":"AoTB0n3X_ZxE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1597107830925,"user_tz":-330,"elapsed":3752863,"user":{"displayName":"Kumar Shwetaketu","photoUrl":"","userId":"02755040458660561297"}},"outputId":"1ed37df6-f5f0-4214-9f02-bb7143ee8dff"},"source":["## Adding 5 more epochs\n","## 55  epochs total (50 +5)\n","model.fit_generator(datagen.flow(X_train, y_train, batch_size), steps_per_epoch = X_train.shape[0]/batch_size, epochs = 5, validation_data =(X_test, y_test))"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Epoch 1/5\n","391/390 [==============================] - 68s 173ms/step - loss: 0.2947 - accuracy: 0.8970 - val_loss: 0.4712 - val_accuracy: 0.8547\n","Epoch 2/5\n","391/390 [==============================] - 68s 173ms/step - loss: 0.2914 - accuracy: 0.8990 - val_loss: 0.3914 - val_accuracy: 0.8746\n","Epoch 3/5\n","391/390 [==============================] - 68s 173ms/step - loss: 0.2876 - accuracy: 0.9001 - val_loss: 0.4355 - val_accuracy: 0.8705\n","Epoch 4/5\n","391/390 [==============================] - 68s 173ms/step - loss: 0.2799 - accuracy: 0.9014 - val_loss: 0.4131 - val_accuracy: 0.8743\n","Epoch 5/5\n","391/390 [==============================] - 67s 172ms/step - loss: 0.2817 - accuracy: 0.8995 - val_loss: 0.4418 - val_accuracy: 0.8626\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f89da5584a8>"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"C4fB3485CA_f","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1597107834292,"user_tz":-330,"elapsed":3756215,"user":{"displayName":"Kumar Shwetaketu","photoUrl":"","userId":"02755040458660561297"}},"outputId":"d995b752-ad4b-4e92-b1d3-f4d95832e636"},"source":["# Test the model\n","\n","\n","model.evaluate(X_test, y_test)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["313/313 [==============================] - 3s 11ms/step - loss: 0.4418 - accuracy: 0.8626\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[0.4417913556098938, 0.8626000285148621]"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"bbglh0PpCOXe","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":241},"executionInfo":{"status":"ok","timestamp":1597108211867,"user_tz":-330,"elapsed":337453,"user":{"displayName":"Kumar Shwetaketu","photoUrl":"","userId":"02755040458660561297"}},"outputId":"fa9c39ec-3b96-4c13-ae7b-c6094bcd945c"},"source":["## Retrain for 5 epochs with reduced learning rate.\n","## Total 6o epochs\n","import keras\n","keras.backend.set_value(model.optimizer.lr, 0.005)\n","\n","from keras.preprocessing.image import ImageDataGenerator\n","\n","model.fit_generator(datagen.flow(X_train, y_train, batch_size), steps_per_epoch = X_train.shape[0]/batch_size, epochs = 5, validation_data =(X_test, y_test))"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Epoch 1/5\n","  2/390 [..............................] - ETA: 58s - loss: 0.3140 - accuracy: 0.8984WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0690s vs `on_train_batch_end` time: 0.1067s). Check your callbacks.\n","391/390 [==============================] - 67s 170ms/step - loss: 0.2813 - accuracy: 0.9006 - val_loss: 0.3898 - val_accuracy: 0.8781\n","Epoch 2/5\n","391/390 [==============================] - 67s 171ms/step - loss: 0.2706 - accuracy: 0.9061 - val_loss: 0.4209 - val_accuracy: 0.8659\n","Epoch 3/5\n","391/390 [==============================] - 67s 172ms/step - loss: 0.2722 - accuracy: 0.9045 - val_loss: 0.4547 - val_accuracy: 0.8563\n","Epoch 4/5\n","391/390 [==============================] - 67s 173ms/step - loss: 0.2733 - accuracy: 0.9039 - val_loss: 0.4036 - val_accuracy: 0.8702\n","Epoch 5/5\n","391/390 [==============================] - 67s 172ms/step - loss: 0.2640 - accuracy: 0.9078 - val_loss: 0.5477 - val_accuracy: 0.8400\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f89da4736d8>"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"LBR-l9x4EeXW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1597112110864,"user_tz":-330,"elapsed":339370,"user":{"displayName":"Kumar Shwetaketu","photoUrl":"","userId":"02755040458660561297"}},"outputId":"ad3fcc2d-349e-4539-d7dc-fba38d9a344e"},"source":["## Continue training with LR =0.005\n","## Total 65 epochs\n","model.fit_generator(datagen.flow(X_train, y_train, batch_size), steps_per_epoch = X_train.shape[0]/batch_size, epochs = 5, validation_data =(X_test, y_test))"],"execution_count":24,"outputs":[{"output_type":"stream","text":["Epoch 1/5\n","391/390 [==============================] - 68s 173ms/step - loss: 0.2180 - accuracy: 0.9234 - val_loss: 0.4041 - val_accuracy: 0.8758\n","Epoch 2/5\n","391/390 [==============================] - 67s 172ms/step - loss: 0.2168 - accuracy: 0.9242 - val_loss: 0.4466 - val_accuracy: 0.8702\n","Epoch 3/5\n","391/390 [==============================] - 67s 172ms/step - loss: 0.2190 - accuracy: 0.9228 - val_loss: 0.4324 - val_accuracy: 0.8682\n","Epoch 4/5\n","391/390 [==============================] - 67s 172ms/step - loss: 0.2114 - accuracy: 0.9252 - val_loss: 0.4716 - val_accuracy: 0.8629\n","Epoch 5/5\n","391/390 [==============================] - 67s 172ms/step - loss: 0.2121 - accuracy: 0.9268 - val_loss: 0.4457 - val_accuracy: 0.8681\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f89da35cba8>"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"lhP8_bIyDrCe","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1597113011136,"user_tz":-330,"elapsed":339370,"user":{"displayName":"Kumar Shwetaketu","photoUrl":"","userId":"02755040458660561297"}},"outputId":"cefdc1e4-59c4-4121-9d3a-d7adf961e11c"},"source":["## Retrain for 5 epochs with reduced learning rate.\n","## Total 70 epochs\n","keras.backend.set_value(model.optimizer.lr, 0.005)\n","\n","from keras.preprocessing.image import ImageDataGenerator\n"," \n","model.fit_generator(datagen.flow(X_train, y_train, batch_size), steps_per_epoch = X_train.shape[0]/batch_size, epochs = 5, validation_data =(X_test, y_test))"],"execution_count":25,"outputs":[{"output_type":"stream","text":["Epoch 1/5\n","391/390 [==============================] - 68s 173ms/step - loss: 0.4741 - accuracy: 0.8371 - val_loss: 0.7520 - val_accuracy: 0.7726\n","Epoch 2/5\n","391/390 [==============================] - 67s 172ms/step - loss: 0.4198 - accuracy: 0.8541 - val_loss: 0.5075 - val_accuracy: 0.8325\n","Epoch 3/5\n","391/390 [==============================] - 67s 173ms/step - loss: 0.4004 - accuracy: 0.8601 - val_loss: 0.6964 - val_accuracy: 0.7909\n","Epoch 4/5\n","391/390 [==============================] - 67s 172ms/step - loss: 0.3950 - accuracy: 0.8635 - val_loss: 0.6594 - val_accuracy: 0.8058\n","Epoch 5/5\n","391/390 [==============================] - 67s 172ms/step - loss: 0.3844 - accuracy: 0.8660 - val_loss: 0.8944 - val_accuracy: 0.7622\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f89da542b38>"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"Rnv75EOwWg3i","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":374},"executionInfo":{"status":"ok","timestamp":1597113826434,"user_tz":-330,"elapsed":2370,"user":{"displayName":"Kumar Shwetaketu","photoUrl":"","userId":"02755040458660561297"}},"outputId":"9997caad-837e-4d93-acc0-ad1a1e75d9ea"},"source":["## Reducing learning rate and train for 10 more epochs\n","## Total 80 epochs\n","keras.backend.set_value(model.optimizer.lr, 0.002)\n","\n","from keras.preprocessing.image import ImageDataGenerator\n","model.fit_generator(datagen.flow(X_train, y_train, batch_size), steps_per_epoch = X_train.shape[0]/batch_size, epochs = 10, validation_data =(X_test, y_test))"],"execution_count":26,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","391/390 [==============================] - 67s 172ms/step - loss: 0.2871 - accuracy: 0.9001 - val_loss: 0.3743 - val_accuracy: 0.8775\n","Epoch 2/10\n","391/390 [==============================] - 67s 172ms/step - loss: 0.2688 - accuracy: 0.9057 - val_loss: 0.4853 - val_accuracy: 0.8507\n","Epoch 3/10\n","391/390 [==============================] - 67s 172ms/step - loss: 0.2633 - accuracy: 0.9081 - val_loss: 0.5016 - val_accuracy: 0.8480\n","Epoch 4/10\n","391/390 [==============================] - 67s 172ms/step - loss: 0.2596 - accuracy: 0.9098 - val_loss: 0.5207 - val_accuracy: 0.8515\n","Epoch 5/10\n","391/390 [==============================] - 67s 172ms/step - loss: 0.2549 - accuracy: 0.9108 - val_loss: 0.4659 - val_accuracy: 0.8587\n","Epoch 6/10\n","391/390 [==============================] - 67s 172ms/step - loss: 0.2518 - accuracy: 0.9104 - val_loss: 0.3625 - val_accuracy: 0.8875\n","Epoch 7/10\n","391/390 [==============================] - 67s 172ms/step - loss: 0.2448 - accuracy: 0.9152 - val_loss: 0.4731 - val_accuracy: 0.8612\n","Epoch 8/10\n","391/390 [==============================] - 67s 172ms/step - loss: 0.2436 - accuracy: 0.9128 - val_loss: 0.3853 - val_accuracy: 0.8787\n","Epoch 9/10\n","391/390 [==============================] - 67s 172ms/step - loss: 0.2445 - accuracy: 0.9138 - val_loss: 0.3998 - val_accuracy: 0.8805\n","Epoch 10/10\n","391/390 [==============================] - 67s 172ms/step - loss: 0.2410 - accuracy: 0.9153 - val_loss: 0.4276 - val_accuracy: 0.8717\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f89da33f2b0>"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"vpqn_67KZ1YN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":595},"executionInfo":{"status":"error","timestamp":1597114279213,"user_tz":-330,"elapsed":422983,"user":{"displayName":"Kumar Shwetaketu","photoUrl":"","userId":"02755040458660561297"}},"outputId":"f4132788-0b0c-4fda-aa11-7fd38e944f0a"},"source":["## 10 more epochs with reduced LR\n","## Total 90 epochs\n","keras.backend.set_value(model.optimizer.lr, 0.001)\n","\n","from keras.preprocessing.image import ImageDataGenerator\n","model.fit_generator(datagen.flow(X_train, y_train, batch_size), steps_per_epoch = X_train.shape[0]/batch_size, epochs = 10, validation_data =(X_test, y_test))"],"execution_count":27,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","391/390 [==============================] - 68s 173ms/step - loss: 0.2014 - accuracy: 0.9296 - val_loss: 0.3146 - val_accuracy: 0.9045\n","Epoch 2/10\n","391/390 [==============================] - 67s 172ms/step - loss: 0.1937 - accuracy: 0.9319 - val_loss: 0.3371 - val_accuracy: 0.8999\n","Epoch 3/10\n","391/390 [==============================] - 67s 172ms/step - loss: 0.1899 - accuracy: 0.9333 - val_loss: 0.3308 - val_accuracy: 0.9020\n","Epoch 4/10\n","391/390 [==============================] - 67s 172ms/step - loss: 0.1798 - accuracy: 0.9354 - val_loss: 0.3502 - val_accuracy: 0.8958\n","Epoch 5/10\n","391/390 [==============================] - 67s 173ms/step - loss: 0.1776 - accuracy: 0.9376 - val_loss: 0.4075 - val_accuracy: 0.8839\n","Epoch 6/10\n","391/390 [==============================] - 67s 172ms/step - loss: 0.1817 - accuracy: 0.9356 - val_loss: 0.3264 - val_accuracy: 0.9025\n","Epoch 7/10\n"," 91/390 [=====>........................] - ETA: 49s - loss: 0.1754 - accuracy: 0.9388"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-27-0a01c3a61cb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1827\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1828\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1829\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1831\u001b[0m   @deprecation.deprecated(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"BS_oB_N1FnQ4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1597114507191,"user_tz":-330,"elapsed":782,"user":{"displayName":"Kumar Shwetaketu","photoUrl":"","userId":"02755040458660561297"}},"outputId":"43a4bc1f-e6b0-401d-f79e-d5b43b5b0eb5"},"source":["# Save the trained weights in to .h5 format\n","model.save_weights(\"DNST_model_llr.h5\")\n","print(\"Saved model to disk\")"],"execution_count":29,"outputs":[{"output_type":"stream","text":["Saved model to disk\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vYq-wkegcVvd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1597114645014,"user_tz":-330,"elapsed":4165,"user":{"displayName":"Kumar Shwetaketu","photoUrl":"","userId":"02755040458660561297"}},"outputId":"f7fa7bad-17cb-4d61-8d62-78339fc8765b"},"source":["# Test the model\n","\n","\n","model.evaluate(X_test, y_test)"],"execution_count":31,"outputs":[{"output_type":"stream","text":["313/313 [==============================] - 3s 11ms/step - loss: 0.3419 - accuracy: 0.8997\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[0.3418941795825958, 0.8996999859809875]"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"OIn53n25c2ka","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1597114988504,"user_tz":-330,"elapsed":339492,"user":{"displayName":"Kumar Shwetaketu","photoUrl":"","userId":"02755040458660561297"}},"outputId":"c2cbed36-40e9-4577-f319-d2e50ad945f1"},"source":["model.fit_generator(datagen.flow(X_train, y_train, batch_size), steps_per_epoch = X_train.shape[0]/batch_size, epochs = 5, validation_data =(X_test, y_test))"],"execution_count":32,"outputs":[{"output_type":"stream","text":["Epoch 1/5\n","391/390 [==============================] - 68s 173ms/step - loss: 0.1749 - accuracy: 0.9384 - val_loss: 0.4608 - val_accuracy: 0.8750\n","Epoch 2/5\n","391/390 [==============================] - 67s 172ms/step - loss: 0.1701 - accuracy: 0.9389 - val_loss: 0.4087 - val_accuracy: 0.8853\n","Epoch 3/5\n","391/390 [==============================] - 67s 172ms/step - loss: 0.1715 - accuracy: 0.9396 - val_loss: 0.4030 - val_accuracy: 0.8880\n","Epoch 4/5\n","391/390 [==============================] - 67s 172ms/step - loss: 0.1705 - accuracy: 0.9389 - val_loss: 0.4171 - val_accuracy: 0.8865\n","Epoch 5/5\n","391/390 [==============================] - 67s 173ms/step - loss: 0.1680 - accuracy: 0.9418 - val_loss: 0.3939 - val_accuracy: 0.8875\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f89da3555f8>"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"33OnD-NzeTqI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":374},"executionInfo":{"status":"ok","timestamp":1597115707699,"user_tz":-330,"elapsed":385058,"user":{"displayName":"Kumar Shwetaketu","photoUrl":"","userId":"02755040458660561297"}},"outputId":"1cabfbf7-eef5-47a7-fcf0-53aa4387faff"},"source":["model.fit_generator(datagen.flow(X_train, y_train, batch_size), steps_per_epoch = X_train.shape[0]/batch_size, epochs = 10, validation_data =(X_test, y_test))"],"execution_count":33,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","391/390 [==============================] - 68s 174ms/step - loss: 0.1652 - accuracy: 0.9416 - val_loss: 0.3597 - val_accuracy: 0.8971\n","Epoch 2/10\n","391/390 [==============================] - 67s 172ms/step - loss: 0.1629 - accuracy: 0.9422 - val_loss: 0.3764 - val_accuracy: 0.8928\n","Epoch 3/10\n","391/390 [==============================] - 67s 172ms/step - loss: 0.1616 - accuracy: 0.9430 - val_loss: 0.3448 - val_accuracy: 0.9000\n","Epoch 4/10\n","391/390 [==============================] - 67s 172ms/step - loss: 0.1637 - accuracy: 0.9424 - val_loss: 0.4323 - val_accuracy: 0.8834\n","Epoch 5/10\n","391/390 [==============================] - 68s 173ms/step - loss: 0.1616 - accuracy: 0.9430 - val_loss: 0.3469 - val_accuracy: 0.9017\n","Epoch 6/10\n","391/390 [==============================] - 68s 173ms/step - loss: 0.1558 - accuracy: 0.9439 - val_loss: 0.3130 - val_accuracy: 0.9097\n","Epoch 7/10\n","391/390 [==============================] - 68s 173ms/step - loss: 0.1554 - accuracy: 0.9451 - val_loss: 0.4083 - val_accuracy: 0.8888\n","Epoch 8/10\n","391/390 [==============================] - 68s 173ms/step - loss: 0.1582 - accuracy: 0.9434 - val_loss: 0.4432 - val_accuracy: 0.8788\n","Epoch 9/10\n","391/390 [==============================] - 68s 173ms/step - loss: 0.1571 - accuracy: 0.9445 - val_loss: 0.3531 - val_accuracy: 0.9008\n","Epoch 10/10\n","391/390 [==============================] - 68s 173ms/step - loss: 0.1542 - accuracy: 0.9458 - val_loss: 0.3892 - val_accuracy: 0.8946\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f89da355080>"]},"metadata":{"tags":[]},"execution_count":33}]}]}